{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "b6df1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv \n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "6f482b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp \n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "d9a96e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "input_file_folder = \"/Users/keltoumboukra/Desktop/Coding projects - Git/SamplePoolingForNGS/Files/\"\n",
    "input_file_name = \"InputTestFile.csv\"\n",
    "\n",
    "# final desired vol (nL)\n",
    "final_pool_vol = 10000\n",
    "\n",
    "# well position of pool in output plate\n",
    "pool_well_in_output_plate = \"A1\"\n",
    "\n",
    "# minimum volume to be pipetted (nL)\n",
    "min_pipetting_capacity = float(25) # for Echo\n",
    "\n",
    "# minimum volume that can be pipetted \n",
    "vol_available_in_well = 10000 # for e.g, if there is 20 uL in the well, 5000 nL is what can be available as 15 uL is the minimum working range in the PP-0200 Echo plate)\n",
    "\n",
    "# Dataframes\n",
    "input_file_df = pd.read_csv(input_file_folder + input_file_name)\n",
    "input_file_df.rename(columns={input_file_df.columns[2]: \"Concentration\"},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "855698a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/keltoumboukra/Desktop/Coding projects - Git/SamplePoolingForNGS/Files/NGSpooling_20221122-110458/InputFiles/InputFile.csv'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outputs\n",
    "\n",
    "output_files_folder = \"/Users/keltoumboukra/Desktop/Coding projects - Git/SamplePoolingForNGS/Files/\"\n",
    "output_files_folder = output_files_folder + \"NGSpooling_\" + timestr\n",
    "os.mkdir(output_files_folder)\n",
    "output_files_folder = output_files_folder + \"/\"\n",
    "\n",
    "output_file_name = \"ProcessingDetails.csv\"\n",
    "output_file_df = pd.DataFrame(columns=['Sample Well ID','Sample Concentration','Sample Calculated Weight', 'Sample Calculated Weight Normalised', 'Sample Calculated Volume In Pool'])\n",
    "\n",
    "output_echo_file_name = \"EchoFile.csv\"\n",
    "output_echo_file_df = pd.DataFrame(columns=['Source Well','Destination Well','Transfer Volume'])\n",
    "\n",
    "output_report_name = \"ExceptionsReport.csv\"\n",
    "output_report_df = pd.DataFrame(columns=['Sample Well ID','Sample Concentration','Comment'])\n",
    "\n",
    "# Copy input file into the output folder\n",
    "os.mkdir(output_files_folder + \"InputFiles/\")\n",
    "shutil.copyfile(input_file_folder+input_file_name, output_files_folder + \"InputFiles/\" + \"InputFile.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "c0fc0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim input data frame \n",
    "\n",
    "# Remove standards \n",
    "input_file_df = input_file_df[input_file_df[\"Content\"].str.contains(\"Standard\") == False]\n",
    "input_file_df = input_file_df.reset_index(drop=True)\n",
    "\n",
    "# Remove samples with negative concentrations and add to output report\n",
    "for row in input_file_df.itertuples():\n",
    "    \n",
    "    Index = row [0]\n",
    "    Well = row[1]\n",
    "    Concentration = row[3]\n",
    "    \n",
    "    if Concentration <= 0:\n",
    "        output_report_df = output_report_df.append({'Sample Well ID': Well, 'Sample Concentration': Concentration, 'Comment': \"Sample has negative value for concentration\"}, ignore_index=True)\n",
    "        input_file_df = input_file_df.drop(Index)\n",
    "\n",
    "input_file_df = input_file_df.reset_index(drop=True)\n",
    "output_report_df = output_report_df.reset_index(drop=True)\n",
    "\n",
    "# Copy trimmed input file into the output folder\n",
    "input_file_df.to_csv(output_files_folder + \"InputFiles/\" + \"InputTrimmedFile.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "d0c95a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Weights \n",
    "\n",
    "max_concentration = input_file_df['Concentration'].max()\n",
    "sum_weights = float()\n",
    "\n",
    "for row in input_file_df.itertuples():\n",
    "    \n",
    "    Index = row [0]\n",
    "    Well = row[1]\n",
    "    Concentration = row[3]\n",
    "\n",
    "    sample_weight = max_concentration/Concentration\n",
    "    sum_weights += sample_weight\n",
    "    output_file_df = output_file_df.append({'Sample Well ID': Well, 'Sample Concentration': Concentration, 'Sample Calculated Weight': sample_weight}, ignore_index=True)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ece0ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Normalised Weights \n",
    "\n",
    "sum_normalised_weights = float(0)\n",
    "for row in input_file_df.itertuples():\n",
    "    \n",
    "    Index = row [0]\n",
    "    Well = row[1]\n",
    "    Concentration = row[3]\n",
    "    \n",
    "    sample_normalised_weight = output_file_df[\"Sample Calculated Weight\"].iloc[Index]/sum_weights\n",
    "    sum_normalised_weights += sample_normalised_weight # for QC, should be =1\n",
    "    output_file_df.at[Index,'Sample Calculated Weight Normalised']=sample_normalised_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "a3ba5600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Volume to pipette for each sample in the final pool\n",
    "\n",
    "vol_in_pool = float()\n",
    "sum_vol_in_pool = float(0)\n",
    "fail_bool = bool(0)\n",
    "\n",
    "for row in input_file_df.itertuples():\n",
    "    \n",
    "    Index = row [0]\n",
    "    Well = row[1]\n",
    "    Concentration = row[3]\n",
    "    \n",
    "    vol_in_pool = output_file_df[\"Sample Calculated Weight Normalised\"].iloc[Index]*final_pool_vol \n",
    "    sum_vol_in_pool += vol_in_pool # for QC, should be = final_pool_vol  \n",
    "    \n",
    "    if vol_in_pool < min_pipetting_capacity:\n",
    "        output_report_df = output_report_df.append({'Sample Well ID': Well, 'Sample Concentration': Concentration, 'Comment': \"Volume to be pipetted for this well ({} nL) is smaller than pipetting capacity ({} nL). You MUST reprocess the file\".format(vol_in_pool,min_pipetting_capacity)}, ignore_index=True)\n",
    "        fail_bool = bool(1)\n",
    "    elif vol_in_pool > vol_available_in_well:\n",
    "        output_report_df = output_report_df.append({'Sample Well ID': Well, 'Sample Concentration': Concentration, 'Comment': \"Volume to be pipetted for this well ({} nL) is larger than the volume available ({} nL). You MUST reprocess the file\".format(vol_in_pool,vol_available_in_well)}, ignore_index=True)\n",
    "        fail_bool = bool(1)\n",
    "    else:\n",
    "        output_file_df.at[Index,'Sample Calculated Volume In Pool']=vol_in_pool\n",
    "        output_echo_file_df = output_echo_file_df.append({'Source Well': Well, 'Destination Well': pool_well_in_output_plate, 'Transfer Volume': vol_in_pool}, ignore_index=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "0512a91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing successful! Check output file folder for processing details, report and Echo ready file\n"
     ]
    }
   ],
   "source": [
    "os.mkdir(output_files_folder + \"OutputFiles/\")\n",
    "\n",
    "if fail_bool == bool(1):\n",
    "    print(\"Processing failed. The concentration of 1 sample or more is out of range and doesn't allow pooling with the settings entered. Check report file for details.\")\n",
    "else:\n",
    "    print(\"Processing successful! Check output file folder for processing details, report and Echo ready file\")\n",
    "    output_file_df.to_csv(output_files_folder + \"OutputFiles/\" + output_file_name, index=False)\n",
    "    output_echo_file_df.to_csv(output_files_folder + \"OutputFiles/\" + output_echo_file_name, index=False)\n",
    "\n",
    "output_report_df.to_csv(output_files_folder + \"OutputFiles/\" + output_report_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d062c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee8e466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9dc8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
