{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "b6df1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "d9a96e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "\n",
    "input_file_folder = \"/Users/keltoumboukra/Desktop/Coding projects - Git/SamplePoolingForNGS/Files/\"\n",
    "input_file_name = \"qubit_data.CSV\"\n",
    "\n",
    "# final desired vol (nL)\n",
    "final_pool_vol = 100000\n",
    "\n",
    "# well position of pool in output plate\n",
    "pool_well_in_output_plate = \"A1\"\n",
    "\n",
    "# minimum volume to be pipetted (nL)\n",
    "min_pipetting_capacity = float(25) # for Echo\n",
    "\n",
    "# minimum volume that can be pipetted \n",
    "vol_available_in_well = 5000 # for e.g, if there is 20 uL in the well, 5000 nL is what can be available as 15 uL is the minimum working range in the PP-0200 Echo plate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "e516ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Dataframes\n",
    "\n",
    "input_file_df = pd.read_csv(input_file_folder + input_file_name)\n",
    "input_file_df.rename(columns={input_file_df.columns[2]: \"Concentration\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "6ddb03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete standards/negative values from the input dataframe\n",
    "for row in input_file_df.itertuples():\n",
    "    \n",
    "    Index = row [0]\n",
    "    Well = row[1]\n",
    "    Content = row[2]\n",
    "    Concentration = row[3]\n",
    "    \n",
    "    #if \"Standard\" in Content:\n",
    "        #input_file_df = input_file_df.drop(Index)\n",
    "        #input_file_df = input_file_df.reset_index(drop=True)\n",
    "    #if Concentration < 0:\n",
    "        #input_file_df = input_file_df.drop(Index)\n",
    "        #input_file_df = input_file_df.reset_index(drop=True)\n",
    "        #log in report file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "855698a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs\n",
    "\n",
    "output_files_folder = \"/Users/keltoumboukra/Desktop/Coding projects - Git/SamplePoolingForNGS/Files/\"\n",
    "output_file_name = \"OutputExample.csv\"\n",
    "output_file_df = pd.DataFrame(columns=['Sample Well ID','Sample Concentration','Sample Calculated Weight', 'Sample Calculated Weight Normalised', 'Sample Calculated Volume In Pool'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "8d9d5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Dataframes\n",
    "\n",
    "output_echo_file_name = \"QubitOutputEcho.csv\"\n",
    "output_echo_file_df = pd.DataFrame(columns=['Source Well','Destination Well','Transfer Volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "d0c95a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Weights \n",
    "\n",
    "def _CalculateWeights(InputDataframe, OutputDataframe):\n",
    "    \n",
    "    _input_file_df = InputDataframe\n",
    "    _output_file_df = OutputDataframe \n",
    "\n",
    "    max_concentration = _input_file_df['Concentration'].max()\n",
    "    sum_weights = float()\n",
    "\n",
    "    for row in _input_file_df.itertuples():\n",
    "\n",
    "        Index = row [0]\n",
    "        Well = row[1]\n",
    "        Concentration = row[3]\n",
    "\n",
    "        sample_weight = max_concentration/Concentration\n",
    "        sum_weights += sample_weight\n",
    "        _output_file_df = _output_file_df.append({'Sample Well ID': Well, 'Sample Concentration': Concentration, 'Sample Calculated Weight': sample_weight}, ignore_index=True)    \n",
    "    \n",
    "    return _output_file_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "ece0ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Normalised Weights \n",
    "\n",
    "def _CalculateNormWeights(InputDataframe, OutputDataframe):\n",
    "    \n",
    "    _input_file_df = InputDataframe\n",
    "    _output_file_df = OutputDataframe \n",
    "\n",
    "    sum_normalised_weights = float(0)\n",
    "    for row in _input_file_df.itertuples():\n",
    "\n",
    "        Index = row [0]\n",
    "        Well = row[1]\n",
    "        Concentration = row[3]\n",
    "\n",
    "        sample_normalised_weight = _output_file_df[\"Sample Calculated Weight\"].iloc[Index]/sum_weights\n",
    "        sum_normalised_weights += sample_normalised_weight # for QC, should be =1\n",
    "        _output_file_df.at[Index,'Sample Calculated Weight Normalised']=sample_normalised_weight\n",
    "        \n",
    "    return _output_file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "a3ba5600",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'output_file_df' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/96/q5mqhh654rq681_cth8647w80000gp/T/ipykernel_27003/442665089.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate Volume to pipette for each sample in the final pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0m_CalculateWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0m_CalculateNormWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/96/q5mqhh654rq681_cth8647w80000gp/T/ipykernel_27003/174124772.py\u001b[0m in \u001b[0;36m_CalculateWeights\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_concentration\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mConcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msum_weights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput_file_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_file_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Sample Well ID'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sample Concentration'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sample Calculated Weight'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'output_file_df' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Calculate Volume to pipette for each sample in the final pool\n",
    "\n",
    "vol_in_pool = float()\n",
    "sum_vol_in_pool = float(0)\n",
    "\n",
    "for row in input_file_df.itertuples():\n",
    "    \n",
    "    Index = row [0]\n",
    "    Well = row[1]\n",
    "    Concentration = row[3]\n",
    "    \n",
    "    vol_in_pool = output_file_df[\"Sample Calculated Weight Normalised\"].iloc[Index]*final_pool_vol \n",
    "    sum_vol_in_pool += vol_in_pool # for QC, should be = final_pool_vol\n",
    "    output_file_df.at[Index,'Sample Calculated Volume In Pool']=vol_in_pool  \n",
    "    \n",
    "    if vol_in_pool < min_pipetting_capacity:\n",
    "        #log in report that the sample will be ignored\n",
    "        print(\"exception 1: well {} ignored\".format(Well))\n",
    "    elif vol_in_pool > vol_available_in_well:\n",
    "        #log in report that the sample will be ignored\n",
    "        print(\"exception 2: well {} ignored\".format(Well))\n",
    "    else:\n",
    "        output_echo_file_df = output_echo_file_df.append({'Source Well': Well, 'Destination Well': pool_well_in_output_plate, 'Transfer Volume': vol_in_pool}, ignore_index=True)     \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3c4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "0512a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_df.to_csv(output_files_folder + output_file_name, index=False)\n",
    "output_echo_file_df.to_csv(output_files_folder + output_echo_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba35a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
